name:"mxnet-mdoel"
layer{
name: "data"
type: "Input"
top: "data"
input_param {
  shape {
    dim: 1
    dim: 3
    dim: 112
    dim: 112
  }
}
}
layer{
name: "conv_1_conv2d"
type: "Convolution"
bottom: "data"
top: "conv_1_conv2d"
convolution_param {
  num_output: 64
  bias_term: true
  pad: 1
  kernel_size: 3
  group: 1
  stride: 2
}
}
layer{
name: "conv_1_relu"
type: "PReLU"
bottom: "conv_1_conv2d"
top: "conv_1_relu"
}
layer{
name: "res_2_block0_conv_sep_conv2d"
type: "Convolution"
bottom: "conv_1_relu"
top: "res_2_block0_conv_sep_conv2d"
convolution_param {
  num_output: 64
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "res_2_block0_conv_sep_relu"
type: "PReLU"
bottom: "res_2_block0_conv_sep_conv2d"
top: "res_2_block0_conv_sep_relu"
}
layer{
name: "res_2_block0_conv_dw_conv2d"
type: "Convolution"
bottom: "res_2_block0_conv_sep_relu"
top: "res_2_block0_conv_dw_conv2d"
convolution_param {
  num_output: 64
  bias_term: true
  pad: 1
  kernel_size: 3
  group: 64
  stride: 1
}
}
layer{
name: "res_2_block0_conv_dw_relu"
type: "PReLU"
bottom: "res_2_block0_conv_dw_conv2d"
top: "res_2_block0_conv_dw_relu"
}
layer{
name: "res_2_block0_conv_proj_conv2d"
type: "Convolution"
bottom: "res_2_block0_conv_dw_relu"
top: "res_2_block0_conv_proj_conv2d"
convolution_param {
  num_output: 64
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "_plus0"
type: "Eltwise"
bottom: "res_2_block0_conv_proj_conv2d"
bottom: "conv_1_relu"
top: "_plus0"
eltwise_param {
  operation: SUM
}
}
layer{
name: "res_2_block1_conv_sep_conv2d"
type: "Convolution"
bottom: "_plus0"
top: "res_2_block1_conv_sep_conv2d"
convolution_param {
  num_output: 64
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "res_2_block1_conv_sep_relu"
type: "PReLU"
bottom: "res_2_block1_conv_sep_conv2d"
top: "res_2_block1_conv_sep_relu"
}
layer{
name: "res_2_block1_conv_dw_conv2d"
type: "Convolution"
bottom: "res_2_block1_conv_sep_relu"
top: "res_2_block1_conv_dw_conv2d"
convolution_param {
  num_output: 64
  bias_term: true
  pad: 1
  kernel_size: 3
  group: 64
  stride: 1
}
}
layer{
name: "res_2_block1_conv_dw_relu"
type: "PReLU"
bottom: "res_2_block1_conv_dw_conv2d"
top: "res_2_block1_conv_dw_relu"
}
layer{
name: "res_2_block1_conv_proj_conv2d"
type: "Convolution"
bottom: "res_2_block1_conv_dw_relu"
top: "res_2_block1_conv_proj_conv2d"
convolution_param {
  num_output: 64
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "_plus1"
type: "Eltwise"
bottom: "res_2_block1_conv_proj_conv2d"
bottom: "_plus0"
top: "_plus1"
eltwise_param {
  operation: SUM
}
}
layer{
name: "dconv_23_conv_sep_conv2d"
type: "Convolution"
bottom: "_plus1"
top: "dconv_23_conv_sep_conv2d"
convolution_param {
  num_output: 128
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "dconv_23_conv_sep_relu"
type: "PReLU"
bottom: "dconv_23_conv_sep_conv2d"
top: "dconv_23_conv_sep_relu"
}
layer{
name: "dconv_23_conv_dw_conv2d"
type: "Convolution"
bottom: "dconv_23_conv_sep_relu"
top: "dconv_23_conv_dw_conv2d"
convolution_param {
  num_output: 128
  bias_term: true
  pad: 1
  kernel_size: 3
  group: 128
  stride: 2
}
}
layer{
name: "dconv_23_conv_dw_relu"
type: "PReLU"
bottom: "dconv_23_conv_dw_conv2d"
top: "dconv_23_conv_dw_relu"
}
layer{
name: "dconv_23_conv_proj_conv2d"
type: "Convolution"
bottom: "dconv_23_conv_dw_relu"
top: "dconv_23_conv_proj_conv2d"
convolution_param {
  num_output: 128
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "res_3_block0_conv_sep_conv2d"
type: "Convolution"
bottom: "dconv_23_conv_proj_conv2d"
top: "res_3_block0_conv_sep_conv2d"
convolution_param {
  num_output: 128
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "res_3_block0_conv_sep_relu"
type: "PReLU"
bottom: "res_3_block0_conv_sep_conv2d"
top: "res_3_block0_conv_sep_relu"
}
layer{
name: "res_3_block0_conv_dw_conv2d"
type: "Convolution"
bottom: "res_3_block0_conv_sep_relu"
top: "res_3_block0_conv_dw_conv2d"
convolution_param {
  num_output: 128
  bias_term: true
  pad: 1
  kernel_size: 3
  group: 128
  stride: 1
}
}
layer{
name: "res_3_block0_conv_dw_relu"
type: "PReLU"
bottom: "res_3_block0_conv_dw_conv2d"
top: "res_3_block0_conv_dw_relu"
}
layer{
name: "res_3_block0_conv_proj_conv2d"
type: "Convolution"
bottom: "res_3_block0_conv_dw_relu"
top: "res_3_block0_conv_proj_conv2d"
convolution_param {
  num_output: 128
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "_plus2"
type: "Eltwise"
bottom: "res_3_block0_conv_proj_conv2d"
bottom: "dconv_23_conv_proj_conv2d"
top: "_plus2"
eltwise_param {
  operation: SUM
}
}
layer{
name: "res_3_block1_conv_sep_conv2d"
type: "Convolution"
bottom: "_plus2"
top: "res_3_block1_conv_sep_conv2d"
convolution_param {
  num_output: 128
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "res_3_block1_conv_sep_relu"
type: "PReLU"
bottom: "res_3_block1_conv_sep_conv2d"
top: "res_3_block1_conv_sep_relu"
}
layer{
name: "res_3_block1_conv_dw_conv2d"
type: "Convolution"
bottom: "res_3_block1_conv_sep_relu"
top: "res_3_block1_conv_dw_conv2d"
convolution_param {
  num_output: 128
  bias_term: true
  pad: 1
  kernel_size: 3
  group: 128
  stride: 1
}
}
layer{
name: "res_3_block1_conv_dw_relu"
type: "PReLU"
bottom: "res_3_block1_conv_dw_conv2d"
top: "res_3_block1_conv_dw_relu"
}
layer{
name: "res_3_block1_conv_proj_conv2d"
type: "Convolution"
bottom: "res_3_block1_conv_dw_relu"
top: "res_3_block1_conv_proj_conv2d"
convolution_param {
  num_output: 128
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "_plus3"
type: "Eltwise"
bottom: "res_3_block1_conv_proj_conv2d"
bottom: "_plus2"
top: "_plus3"
eltwise_param {
  operation: SUM
}
}
layer{
name: "res_3_block2_conv_sep_conv2d"
type: "Convolution"
bottom: "_plus3"
top: "res_3_block2_conv_sep_conv2d"
convolution_param {
  num_output: 128
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "res_3_block2_conv_sep_relu"
type: "PReLU"
bottom: "res_3_block2_conv_sep_conv2d"
top: "res_3_block2_conv_sep_relu"
}
layer{
name: "res_3_block2_conv_dw_conv2d"
type: "Convolution"
bottom: "res_3_block2_conv_sep_relu"
top: "res_3_block2_conv_dw_conv2d"
convolution_param {
  num_output: 128
  bias_term: true
  pad: 1
  kernel_size: 3
  group: 128
  stride: 1
}
}
layer{
name: "res_3_block2_conv_dw_relu"
type: "PReLU"
bottom: "res_3_block2_conv_dw_conv2d"
top: "res_3_block2_conv_dw_relu"
}
layer{
name: "res_3_block2_conv_proj_conv2d"
type: "Convolution"
bottom: "res_3_block2_conv_dw_relu"
top: "res_3_block2_conv_proj_conv2d"
convolution_param {
  num_output: 128
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "_plus4"
type: "Eltwise"
bottom: "res_3_block2_conv_proj_conv2d"
bottom: "_plus3"
top: "_plus4"
eltwise_param {
  operation: SUM
}
}
layer{
name: "res_3_block3_conv_sep_conv2d"
type: "Convolution"
bottom: "_plus4"
top: "res_3_block3_conv_sep_conv2d"
convolution_param {
  num_output: 128
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "res_3_block3_conv_sep_relu"
type: "PReLU"
bottom: "res_3_block3_conv_sep_conv2d"
top: "res_3_block3_conv_sep_relu"
}
layer{
name: "res_3_block3_conv_dw_conv2d"
type: "Convolution"
bottom: "res_3_block3_conv_sep_relu"
top: "res_3_block3_conv_dw_conv2d"
convolution_param {
  num_output: 128
  bias_term: true
  pad: 1
  kernel_size: 3
  group: 128
  stride: 1
}
}
layer{
name: "res_3_block3_conv_dw_relu"
type: "PReLU"
bottom: "res_3_block3_conv_dw_conv2d"
top: "res_3_block3_conv_dw_relu"
}
layer{
name: "res_3_block3_conv_proj_conv2d"
type: "Convolution"
bottom: "res_3_block3_conv_dw_relu"
top: "res_3_block3_conv_proj_conv2d"
convolution_param {
  num_output: 128
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "_plus5"
type: "Eltwise"
bottom: "res_3_block3_conv_proj_conv2d"
bottom: "_plus4"
top: "_plus5"
eltwise_param {
  operation: SUM
}
}
layer{
name: "res_3_block4_conv_sep_conv2d"
type: "Convolution"
bottom: "_plus5"
top: "res_3_block4_conv_sep_conv2d"
convolution_param {
  num_output: 128
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "res_3_block4_conv_sep_relu"
type: "PReLU"
bottom: "res_3_block4_conv_sep_conv2d"
top: "res_3_block4_conv_sep_relu"
}
layer{
name: "res_3_block4_conv_dw_conv2d"
type: "Convolution"
bottom: "res_3_block4_conv_sep_relu"
top: "res_3_block4_conv_dw_conv2d"
convolution_param {
  num_output: 128
  bias_term: true
  pad: 1
  kernel_size: 3
  group: 128
  stride: 1
}
}
layer{
name: "res_3_block4_conv_dw_relu"
type: "PReLU"
bottom: "res_3_block4_conv_dw_conv2d"
top: "res_3_block4_conv_dw_relu"
}
layer{
name: "res_3_block4_conv_proj_conv2d"
type: "Convolution"
bottom: "res_3_block4_conv_dw_relu"
top: "res_3_block4_conv_proj_conv2d"
convolution_param {
  num_output: 128
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "_plus6"
type: "Eltwise"
bottom: "res_3_block4_conv_proj_conv2d"
bottom: "_plus5"
top: "_plus6"
eltwise_param {
  operation: SUM
}
}
layer{
name: "res_3_block5_conv_sep_conv2d"
type: "Convolution"
bottom: "_plus6"
top: "res_3_block5_conv_sep_conv2d"
convolution_param {
  num_output: 128
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "res_3_block5_conv_sep_relu"
type: "PReLU"
bottom: "res_3_block5_conv_sep_conv2d"
top: "res_3_block5_conv_sep_relu"
}
layer{
name: "res_3_block5_conv_dw_conv2d"
type: "Convolution"
bottom: "res_3_block5_conv_sep_relu"
top: "res_3_block5_conv_dw_conv2d"
convolution_param {
  num_output: 128
  bias_term: true
  pad: 1
  kernel_size: 3
  group: 128
  stride: 1
}
}
layer{
name: "res_3_block5_conv_dw_relu"
type: "PReLU"
bottom: "res_3_block5_conv_dw_conv2d"
top: "res_3_block5_conv_dw_relu"
}
layer{
name: "res_3_block5_conv_proj_conv2d"
type: "Convolution"
bottom: "res_3_block5_conv_dw_relu"
top: "res_3_block5_conv_proj_conv2d"
convolution_param {
  num_output: 128
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "_plus7"
type: "Eltwise"
bottom: "res_3_block5_conv_proj_conv2d"
bottom: "_plus6"
top: "_plus7"
eltwise_param {
  operation: SUM
}
}
layer{
name: "dconv_34_conv_sep_conv2d"
type: "Convolution"
bottom: "_plus7"
top: "dconv_34_conv_sep_conv2d"
convolution_param {
  num_output: 256
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "dconv_34_conv_sep_relu"
type: "PReLU"
bottom: "dconv_34_conv_sep_conv2d"
top: "dconv_34_conv_sep_relu"
}
layer{
name: "dconv_34_conv_dw_conv2d"
type: "Convolution"
bottom: "dconv_34_conv_sep_relu"
top: "dconv_34_conv_dw_conv2d"
convolution_param {
  num_output: 256
  bias_term: true
  pad: 1
  kernel_size: 3
  group: 256
  stride: 2
}
}
layer{
name: "dconv_34_conv_dw_relu"
type: "PReLU"
bottom: "dconv_34_conv_dw_conv2d"
top: "dconv_34_conv_dw_relu"
}
layer{
name: "dconv_34_conv_proj_conv2d"
type: "Convolution"
bottom: "dconv_34_conv_dw_relu"
top: "dconv_34_conv_proj_conv2d"
convolution_param {
  num_output: 256
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "res_4_block0_conv_sep_conv2d"
type: "Convolution"
bottom: "dconv_34_conv_proj_conv2d"
top: "res_4_block0_conv_sep_conv2d"
convolution_param {
  num_output: 256
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "res_4_block0_conv_sep_relu"
type: "PReLU"
bottom: "res_4_block0_conv_sep_conv2d"
top: "res_4_block0_conv_sep_relu"
}
layer{
name: "res_4_block0_conv_dw_conv2d"
type: "Convolution"
bottom: "res_4_block0_conv_sep_relu"
top: "res_4_block0_conv_dw_conv2d"
convolution_param {
  num_output: 256
  bias_term: true
  pad: 1
  kernel_size: 3
  group: 256
  stride: 1
}
}
layer{
name: "res_4_block0_conv_dw_relu"
type: "PReLU"
bottom: "res_4_block0_conv_dw_conv2d"
top: "res_4_block0_conv_dw_relu"
}
layer{
name: "res_4_block0_conv_proj_conv2d"
type: "Convolution"
bottom: "res_4_block0_conv_dw_relu"
top: "res_4_block0_conv_proj_conv2d"
convolution_param {
  num_output: 256
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "_plus8"
type: "Eltwise"
bottom: "res_4_block0_conv_proj_conv2d"
bottom: "dconv_34_conv_proj_conv2d"
top: "_plus8"
eltwise_param {
  operation: SUM
}
}
layer{
name: "res_4_block1_conv_sep_conv2d"
type: "Convolution"
bottom: "_plus8"
top: "res_4_block1_conv_sep_conv2d"
convolution_param {
  num_output: 256
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "res_4_block1_conv_sep_relu"
type: "PReLU"
bottom: "res_4_block1_conv_sep_conv2d"
top: "res_4_block1_conv_sep_relu"
}
layer{
name: "res_4_block1_conv_dw_conv2d"
type: "Convolution"
bottom: "res_4_block1_conv_sep_relu"
top: "res_4_block1_conv_dw_conv2d"
convolution_param {
  num_output: 256
  bias_term: true
  pad: 1
  kernel_size: 3
  group: 256
  stride: 1
}
}
layer{
name: "res_4_block1_conv_dw_relu"
type: "PReLU"
bottom: "res_4_block1_conv_dw_conv2d"
top: "res_4_block1_conv_dw_relu"
}
layer{
name: "res_4_block1_conv_proj_conv2d"
type: "Convolution"
bottom: "res_4_block1_conv_dw_relu"
top: "res_4_block1_conv_proj_conv2d"
convolution_param {
  num_output: 256
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "_plus9"
type: "Eltwise"
bottom: "res_4_block1_conv_proj_conv2d"
bottom: "_plus8"
top: "_plus9"
eltwise_param {
  operation: SUM
}
}
layer{
name: "res_4_block2_conv_sep_conv2d"
type: "Convolution"
bottom: "_plus9"
top: "res_4_block2_conv_sep_conv2d"
convolution_param {
  num_output: 256
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "res_4_block2_conv_sep_relu"
type: "PReLU"
bottom: "res_4_block2_conv_sep_conv2d"
top: "res_4_block2_conv_sep_relu"
}
layer{
name: "res_4_block2_conv_dw_conv2d"
type: "Convolution"
bottom: "res_4_block2_conv_sep_relu"
top: "res_4_block2_conv_dw_conv2d"
convolution_param {
  num_output: 256
  bias_term: true
  pad: 1
  kernel_size: 3
  group: 256
  stride: 1
}
}
layer{
name: "res_4_block2_conv_dw_relu"
type: "PReLU"
bottom: "res_4_block2_conv_dw_conv2d"
top: "res_4_block2_conv_dw_relu"
}
layer{
name: "res_4_block2_conv_proj_conv2d"
type: "Convolution"
bottom: "res_4_block2_conv_dw_relu"
top: "res_4_block2_conv_proj_conv2d"
convolution_param {
  num_output: 256
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "_plus10"
type: "Eltwise"
bottom: "res_4_block2_conv_proj_conv2d"
bottom: "_plus9"
top: "_plus10"
eltwise_param {
  operation: SUM
}
}
layer{
name: "res_4_block3_conv_sep_conv2d"
type: "Convolution"
bottom: "_plus10"
top: "res_4_block3_conv_sep_conv2d"
convolution_param {
  num_output: 256
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "res_4_block3_conv_sep_relu"
type: "PReLU"
bottom: "res_4_block3_conv_sep_conv2d"
top: "res_4_block3_conv_sep_relu"
}
layer{
name: "res_4_block3_conv_dw_conv2d"
type: "Convolution"
bottom: "res_4_block3_conv_sep_relu"
top: "res_4_block3_conv_dw_conv2d"
convolution_param {
  num_output: 256
  bias_term: true
  pad: 1
  kernel_size: 3
  group: 256
  stride: 1
}
}
layer{
name: "res_4_block3_conv_dw_relu"
type: "PReLU"
bottom: "res_4_block3_conv_dw_conv2d"
top: "res_4_block3_conv_dw_relu"
}
layer{
name: "res_4_block3_conv_proj_conv2d"
type: "Convolution"
bottom: "res_4_block3_conv_dw_relu"
top: "res_4_block3_conv_proj_conv2d"
convolution_param {
  num_output: 256
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "_plus11"
type: "Eltwise"
bottom: "res_4_block3_conv_proj_conv2d"
bottom: "_plus10"
top: "_plus11"
eltwise_param {
  operation: SUM
}
}
layer{
name: "res_4_block4_conv_sep_conv2d"
type: "Convolution"
bottom: "_plus11"
top: "res_4_block4_conv_sep_conv2d"
convolution_param {
  num_output: 256
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "res_4_block4_conv_sep_relu"
type: "PReLU"
bottom: "res_4_block4_conv_sep_conv2d"
top: "res_4_block4_conv_sep_relu"
}
layer{
name: "res_4_block4_conv_dw_conv2d"
type: "Convolution"
bottom: "res_4_block4_conv_sep_relu"
top: "res_4_block4_conv_dw_conv2d"
convolution_param {
  num_output: 256
  bias_term: true
  pad: 1
  kernel_size: 3
  group: 256
  stride: 1
}
}
layer{
name: "res_4_block4_conv_dw_relu"
type: "PReLU"
bottom: "res_4_block4_conv_dw_conv2d"
top: "res_4_block4_conv_dw_relu"
}
layer{
name: "res_4_block4_conv_proj_conv2d"
type: "Convolution"
bottom: "res_4_block4_conv_dw_relu"
top: "res_4_block4_conv_proj_conv2d"
convolution_param {
  num_output: 256
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "_plus12"
type: "Eltwise"
bottom: "res_4_block4_conv_proj_conv2d"
bottom: "_plus11"
top: "_plus12"
eltwise_param {
  operation: SUM
}
}
layer{
name: "res_4_block5_conv_sep_conv2d"
type: "Convolution"
bottom: "_plus12"
top: "res_4_block5_conv_sep_conv2d"
convolution_param {
  num_output: 256
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "res_4_block5_conv_sep_relu"
type: "PReLU"
bottom: "res_4_block5_conv_sep_conv2d"
top: "res_4_block5_conv_sep_relu"
}
layer{
name: "res_4_block5_conv_dw_conv2d"
type: "Convolution"
bottom: "res_4_block5_conv_sep_relu"
top: "res_4_block5_conv_dw_conv2d"
convolution_param {
  num_output: 256
  bias_term: true
  pad: 1
  kernel_size: 3
  group: 256
  stride: 1
}
}
layer{
name: "res_4_block5_conv_dw_relu"
type: "PReLU"
bottom: "res_4_block5_conv_dw_conv2d"
top: "res_4_block5_conv_dw_relu"
}
layer{
name: "res_4_block5_conv_proj_conv2d"
type: "Convolution"
bottom: "res_4_block5_conv_dw_relu"
top: "res_4_block5_conv_proj_conv2d"
convolution_param {
  num_output: 256
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "_plus13"
type: "Eltwise"
bottom: "res_4_block5_conv_proj_conv2d"
bottom: "_plus12"
top: "_plus13"
eltwise_param {
  operation: SUM
}
}
layer{
name: "res_4_block6_conv_sep_conv2d"
type: "Convolution"
bottom: "_plus13"
top: "res_4_block6_conv_sep_conv2d"
convolution_param {
  num_output: 256
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "res_4_block6_conv_sep_relu"
type: "PReLU"
bottom: "res_4_block6_conv_sep_conv2d"
top: "res_4_block6_conv_sep_relu"
}
layer{
name: "res_4_block6_conv_dw_conv2d"
type: "Convolution"
bottom: "res_4_block6_conv_sep_relu"
top: "res_4_block6_conv_dw_conv2d"
convolution_param {
  num_output: 256
  bias_term: true
  pad: 1
  kernel_size: 3
  group: 256
  stride: 1
}
}
layer{
name: "res_4_block6_conv_dw_relu"
type: "PReLU"
bottom: "res_4_block6_conv_dw_conv2d"
top: "res_4_block6_conv_dw_relu"
}
layer{
name: "res_4_block6_conv_proj_conv2d"
type: "Convolution"
bottom: "res_4_block6_conv_dw_relu"
top: "res_4_block6_conv_proj_conv2d"
convolution_param {
  num_output: 256
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "_plus14"
type: "Eltwise"
bottom: "res_4_block6_conv_proj_conv2d"
bottom: "_plus13"
top: "_plus14"
eltwise_param {
  operation: SUM
}
}
layer{
name: "res_4_block7_conv_sep_conv2d"
type: "Convolution"
bottom: "_plus14"
top: "res_4_block7_conv_sep_conv2d"
convolution_param {
  num_output: 256
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "res_4_block7_conv_sep_relu"
type: "PReLU"
bottom: "res_4_block7_conv_sep_conv2d"
top: "res_4_block7_conv_sep_relu"
}
layer{
name: "res_4_block7_conv_dw_conv2d"
type: "Convolution"
bottom: "res_4_block7_conv_sep_relu"
top: "res_4_block7_conv_dw_conv2d"
convolution_param {
  num_output: 256
  bias_term: true
  pad: 1
  kernel_size: 3
  group: 256
  stride: 1
}
}
layer{
name: "res_4_block7_conv_dw_relu"
type: "PReLU"
bottom: "res_4_block7_conv_dw_conv2d"
top: "res_4_block7_conv_dw_relu"
}
layer{
name: "res_4_block7_conv_proj_conv2d"
type: "Convolution"
bottom: "res_4_block7_conv_dw_relu"
top: "res_4_block7_conv_proj_conv2d"
convolution_param {
  num_output: 256
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "_plus15"
type: "Eltwise"
bottom: "res_4_block7_conv_proj_conv2d"
bottom: "_plus14"
top: "_plus15"
eltwise_param {
  operation: SUM
}
}
layer{
name: "res_4_block8_conv_sep_conv2d"
type: "Convolution"
bottom: "_plus15"
top: "res_4_block8_conv_sep_conv2d"
convolution_param {
  num_output: 256
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "res_4_block8_conv_sep_relu"
type: "PReLU"
bottom: "res_4_block8_conv_sep_conv2d"
top: "res_4_block8_conv_sep_relu"
}
layer{
name: "res_4_block8_conv_dw_conv2d"
type: "Convolution"
bottom: "res_4_block8_conv_sep_relu"
top: "res_4_block8_conv_dw_conv2d"
convolution_param {
  num_output: 256
  bias_term: true
  pad: 1
  kernel_size: 3
  group: 256
  stride: 1
}
}
layer{
name: "res_4_block8_conv_dw_relu"
type: "PReLU"
bottom: "res_4_block8_conv_dw_conv2d"
top: "res_4_block8_conv_dw_relu"
}
layer{
name: "res_4_block8_conv_proj_conv2d"
type: "Convolution"
bottom: "res_4_block8_conv_dw_relu"
top: "res_4_block8_conv_proj_conv2d"
convolution_param {
  num_output: 256
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "_plus16"
type: "Eltwise"
bottom: "res_4_block8_conv_proj_conv2d"
bottom: "_plus15"
top: "_plus16"
eltwise_param {
  operation: SUM
}
}
layer{
name: "res_4_block9_conv_sep_conv2d"
type: "Convolution"
bottom: "_plus16"
top: "res_4_block9_conv_sep_conv2d"
convolution_param {
  num_output: 256
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "res_4_block9_conv_sep_relu"
type: "PReLU"
bottom: "res_4_block9_conv_sep_conv2d"
top: "res_4_block9_conv_sep_relu"
}
layer{
name: "res_4_block9_conv_dw_conv2d"
type: "Convolution"
bottom: "res_4_block9_conv_sep_relu"
top: "res_4_block9_conv_dw_conv2d"
convolution_param {
  num_output: 256
  bias_term: true
  pad: 1
  kernel_size: 3
  group: 256
  stride: 1
}
}
layer{
name: "res_4_block9_conv_dw_relu"
type: "PReLU"
bottom: "res_4_block9_conv_dw_conv2d"
top: "res_4_block9_conv_dw_relu"
}
layer{
name: "res_4_block9_conv_proj_conv2d"
type: "Convolution"
bottom: "res_4_block9_conv_dw_relu"
top: "res_4_block9_conv_proj_conv2d"
convolution_param {
  num_output: 256
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "_plus17"
type: "Eltwise"
bottom: "res_4_block9_conv_proj_conv2d"
bottom: "_plus16"
top: "_plus17"
eltwise_param {
  operation: SUM
}
}
layer{
name: "dconv_45_conv_sep_conv2d"
type: "Convolution"
bottom: "_plus17"
top: "dconv_45_conv_sep_conv2d"
convolution_param {
  num_output: 512
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "dconv_45_conv_sep_relu"
type: "PReLU"
bottom: "dconv_45_conv_sep_conv2d"
top: "dconv_45_conv_sep_relu"
}
layer{
name: "dconv_45_conv_dw_conv2d"
type: "Convolution"
bottom: "dconv_45_conv_sep_relu"
top: "dconv_45_conv_dw_conv2d"
convolution_param {
  num_output: 512
  bias_term: true
  pad: 1
  kernel_size: 3
  group: 512
  stride: 2
}
}
layer{
name: "dconv_45_conv_dw_relu"
type: "PReLU"
bottom: "dconv_45_conv_dw_conv2d"
top: "dconv_45_conv_dw_relu"
}
layer{
name: "dconv_45_conv_proj_conv2d"
type: "Convolution"
bottom: "dconv_45_conv_dw_relu"
top: "dconv_45_conv_proj_conv2d"
convolution_param {
  num_output: 512
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "res_5_block0_conv_sep_conv2d"
type: "Convolution"
bottom: "dconv_45_conv_proj_conv2d"
top: "res_5_block0_conv_sep_conv2d"
convolution_param {
  num_output: 512
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "res_5_block0_conv_sep_relu"
type: "PReLU"
bottom: "res_5_block0_conv_sep_conv2d"
top: "res_5_block0_conv_sep_relu"
}
layer{
name: "res_5_block0_conv_dw_conv2d"
type: "Convolution"
bottom: "res_5_block0_conv_sep_relu"
top: "res_5_block0_conv_dw_conv2d"
convolution_param {
  num_output: 512
  bias_term: true
  pad: 1
  kernel_size: 3
  group: 512
  stride: 1
}
}
layer{
name: "res_5_block0_conv_dw_relu"
type: "PReLU"
bottom: "res_5_block0_conv_dw_conv2d"
top: "res_5_block0_conv_dw_relu"
}
layer{
name: "res_5_block0_conv_proj_conv2d"
type: "Convolution"
bottom: "res_5_block0_conv_dw_relu"
top: "res_5_block0_conv_proj_conv2d"
convolution_param {
  num_output: 512
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "_plus18"
type: "Eltwise"
bottom: "res_5_block0_conv_proj_conv2d"
bottom: "dconv_45_conv_proj_conv2d"
top: "_plus18"
eltwise_param {
  operation: SUM
}
}
layer{
name: "res_5_block1_conv_sep_conv2d"
type: "Convolution"
bottom: "_plus18"
top: "res_5_block1_conv_sep_conv2d"
convolution_param {
  num_output: 512
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "res_5_block1_conv_sep_relu"
type: "PReLU"
bottom: "res_5_block1_conv_sep_conv2d"
top: "res_5_block1_conv_sep_relu"
}
layer{
name: "res_5_block1_conv_dw_conv2d"
type: "Convolution"
bottom: "res_5_block1_conv_sep_relu"
top: "res_5_block1_conv_dw_conv2d"
convolution_param {
  num_output: 512
  bias_term: true
  pad: 1
  kernel_size: 3
  group: 512
  stride: 1
}
}
layer{
name: "res_5_block1_conv_dw_relu"
type: "PReLU"
bottom: "res_5_block1_conv_dw_conv2d"
top: "res_5_block1_conv_dw_relu"
}
layer{
name: "res_5_block1_conv_proj_conv2d"
type: "Convolution"
bottom: "res_5_block1_conv_dw_relu"
top: "res_5_block1_conv_proj_conv2d"
convolution_param {
  num_output: 512
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "_plus19"
type: "Eltwise"
bottom: "res_5_block1_conv_proj_conv2d"
bottom: "_plus18"
top: "_plus19"
eltwise_param {
  operation: SUM
}
}
layer{
name: "conv_6sep_conv2d"
type: "Convolution"
bottom: "_plus19"
top: "conv_6sep_conv2d"
convolution_param {
  num_output: 512
  bias_term: true
  pad: 0
  kernel_size: 1
  group: 1
  stride: 1
}
}
layer{
name: "conv_6sep_relu"
type: "PReLU"
bottom: "conv_6sep_conv2d"
top: "conv_6sep_relu"
}
layer{
name: "conv_6dw7_7_conv2d"
type: "Convolution"
bottom: "conv_6sep_relu"
top: "conv_6dw7_7_conv2d"
convolution_param {
  num_output: 512
  bias_term: true
  pad: 0
  kernel_size: 7
  group: 512
  stride: 1
}
}
layer{
name: "pre_fc1"
type: "InnerProduct"
bottom: "conv_6dw7_7_conv2d"
top: "pre_fc1"
inner_product_param {
  num_output: 512
}
}
